ns rust/tokio
nn tutorial
hl https://tokio.rs/tokio/tutorial
at ol
co ?tutorial/references/tutorial_code $

ns +tutorial

nn overview
co ../../../crates/rayon $
cr for speeding up CPU-bound computations by running them
cr in parallel, use Rayon instead of Tokio

nn setup
hl https://tokio.rs/tokio/tutorial/setup
co $ ..
co ../references/mini_redis $
cr mini redis will be what the project tutorial builds

nn hello_tokio
hl https://tokio.rs/tokio/tutorial/hello-tokio
co $ ..
co ../../docs/attribute_macros/main $
co ../references/green_threads $
cr compile-time green threading
co ../../docs/modules/runtime $
cr However, asynchronous functions must be executed
cr by a runtime.
co ../../glossary/runtime $
co ../references/async_await $
co ../../docs/modules/runtime/structs/runtime/methods/block_on $

nn spawning
hl https://tokio.rs/tokio/tutorial/spawning
at ol
co $ ..

ns +spawning
nn accepting_sockets
co $ ..
co ../../../docs/modules/net/structs/TcpListener $
co ../../../docs/modules/net/structs/TcpListener/methods/bind $
co ../../../docs/modules/net/structs/TcpListener/methods/accept $
co ../../../docs/modules/net/structs/TcpStream $

nn concurrency
co $ ..

ns +concurrency

nn tasks
co $ ..
co ?docs/modules/task/functions/spawn $
co ?docs/modules/task/structs/JoinHandle $

nn static_bound
co $ ..
co ?references/rust_misconceptions_static $
cr It is a common misconception that 'static
cr always means "lives forever", but this is not
cr the case. Just because a value is 'static does
cr not mean that you have a memory leak.
co ?std/keywords/move $
cr Changing line 7 to task::spawn(async move {
cr will instruct the compiler to move v into the
cr spawned task. Now, the task owns all of its data,
cr making it 'static.
co ?std/sync/arc $
cr If a single piece of data must be accessible
cr from more than one task concurrently, then it
cr must be shared using synchronization primitives
cr such as Arc.

nn send_bound
co $ ..
co ?references/send_and_sync $
co ?std/marker/send $

zz -concurrency
ns ..

nn store_values
co $ .. 

zz -spawning
ns ..

nn shared_state
hl https://tokio.rs/tokio/tutorial/shared-state
co $ ..
at ol

ns +shared_state

nn strategies
co $ ..

ns +strategies

nn mutex
co $ ..
ln guard shared state with mutex

nn spawn_task_message_passing
co $ ..
ln spawn task to manage state. use message passing
ln to operate on it

zz -strategies
ns ..

nn add_bytes_dep
co $ ..
co ?crates/bytes $
cr The biggest feature it adds over Vec<u8>
cr is shallow cloning. In other words, calling
cr clone() on a Bytes instance does not copy the
cr underlying data. Instead, a Bytes instance is
cr a reference-counted handle to some underlying
cr data. The Bytes type is roughly an Arc<Vec<u8>>
cr but with some added capabilities.

nn initialize_hashmap
co $ ..
co ?tokio/docs/modules/sync/structs/mutex $

nn update_process
co $ ..

nn holding_mutex_across_await
co $ ..
co ../../spawning/concurrency/send_bound $
cr Note that the error discussed here is also
cr discussed in the Send bound section from the
cr spawning chapter.
at ol

ns +holding_mutex_across_await

nn restructure_dont_hold_lock_across_await
co $ ..
ln Restructure your code to not hold the lock across an .await
rm This pattern guarantees that you won't run into
rm the Send error, because the mutex guard does not
rm appear anywhere in an async function. It also
rm protects you from deadlocks, when using crates
rm whose MutexGuard implements Send.
co ?tutorial/references/shared_mutable_state_rust $
cr more detailed example

nn spawn_task_message_passing
ln Spawn a task to manage the state and use message passing to operate on it
co $ ..
co ?strategies/spawn_task_message_passing $

nn tokio_async_mutex
ln Use Tokio's asynchronous mutex.
rm The primary feature of the Tokio mutex is that
rm it can be held across an .await without any issues. 
rm That said, an asynchronous mutex is more
rm expensive than an ordinary mutex, and it is
rm typically better to use one of the two other
rm approaches.
co ?modules/sync/structs/mutex $
cr The current_thread runtime flavor is a
cr lightweight, single-threaded runtime. It is a
cr good choice when only spawning a few tasks and
cr opening a handful of sockets. For example, this
cr option works well when providing a synchronous
cr API bridge on top of an asynchronous client
cr library.

zz -holding_mutex_across_await
ns ..

nn task_threads_contention
co $ ..
co ?tutorial/references/resource_contention $

ns +task_threads_contention

nn mutex_sharding
co ?crates/dashmap $
cr The dashmap crate provides an implementation of
cr a more sophisticated sharded hash map.
co ?crates/flurry $
cr concurrent hashmap, port of Java's ConcurrentHashmap
cr data structure
co ?crates/leapfrog $
cr concurrent hashmap
co $ ..

zz -task_threads_contention
ns ..


zz -shared_state
ns ..

nn channels
hl https://tokio.rs/tokio/tutorial/channels
co $ ..
co ?tutorial/references/in_flight_request $
cr We could use tokio::sync::Mutex, but that would
cr only allow a single in-flight request.
co ?tutorial/references/pipelining $
cr If the client implements pipelining, an async
cr mutex results in underutilizing the connection.
co ?docs/modules/sync/structs/mutex $
cr We could use tokio::sync::Mutex, but that would
cr only allow a single in-flight request.
co ?rust/std/sync/mutex $
cr We cannot use std::sync::Mutex as .await would
cr need to be called with the lock held.


ns +channels

nn message_passing
co $ ..
ln The answer is to use message passing. The pattern
ln involves spawning a dedicated task to manage
ln the client resource. Any task that wishes to
ln issue a request sends a message to the client
ln task. The client task issues the request on
ln behalf of the sender, and the response is sent
ln back to the sender.
co ?tokio/docs/modules/sync $
co ?crates/async_channel $
cr If you need a multi-producer multi-consumer
cr channel where only one consumer sees each
cr message, you can use the async-channel crate.

nn tokio_channel_primitives
co $ ..

ns +tokio_channel_primitives

nn mpsc
hl https://docs.rs/tokio/1/tokio/sync/mpsc/index.html
co $ ..
ln multi-producer, single-consumer channel. Many
ln values can be sent.
co ?sync/modules/mpsc $

nn oneshot
hl https://docs.rs/tokio/1/tokio/sync/oneshot/index.html
co $ ..
ln single-producer, single consumer channel. A
ln single value can be sent.
co ?sync/modules/oneshot $

nn broadcast
hl https://docs.rs/tokio/1/tokio/sync/broadcast/index.html
co $ ..
ln multi-producer, multi-consumer. Many values can
ln be sent. Each receiver sees every value.
co ?sync/modules/broadcast $

nn watch
hl https://docs.rs/tokio/1/tokio/sync/watch/index.html
co $ ..
ln multi-producer, multi-consumer. Many values can
ln be sent, but no history is kept. Receivers only
ln see the most recent value.
co ?sync/modules/watch $

zz -tokio_channel_primitives
ns ..

nn define_message_type
co $ ..
co ?rust/std/keywords/enum $
cr To model this, we first define a Command enum
cr and include a variant for each command type.

nn create_channel
co $ ..
co ?sync/modules/mpsc $
cr In the main function, an mpsc channel is created.
co ?sync/modules/mpsc/functions/channel $
cr channel with buffer size of 32 created
co ?task/functions/spawn $

nn spawn_manager_task
co $ ..
co ?task/functions/spawn $

nn receive_responses
co $ ..
co ?sync/modules/oneshot $
cr The oneshot channel is a single-producer,
cr single-consumer channel optimized for sending a
cr single value. In our case, the single value is
cr the response.

nn backpressure_bounded_channels
co $ ..


zz -channels
ns ..

zz -tutorial
ns ..

zz -rust/tokio
ns ../../
